{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english\n",
    "# https://huggingface.co/bert-base-uncased\n",
    "\n",
    "from huggingsound import SpeechRecognitionModel\n",
    "from transformers import pipeline\n",
    "from transformers import logging\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "w2vmodel = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")\n",
    "logging.set_verbosity_error() #change'error' to 'warning' or remove this if you want to see the warning\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def levenshtein_distance(s, t):\n",
    "    m, n = len(s), len(t)\n",
    "    d = [[0] * (n+1) for _ in range(m+1)]\n",
    "    \n",
    "    for i in range(m+1):\n",
    "        d[i][0] = i\n",
    "    \n",
    "    for j in range(n+1):\n",
    "        d[0][j] = j\n",
    "        \n",
    "    for j in range(1, n+1):\n",
    "        for i in range(1, m+1):\n",
    "            if s[i-1] == t[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                d[i][j] = 1 + min(d[i-1][j], d[i][j-1], d[i-1][j-1])\n",
    "                \n",
    "    return d[m][n]\n",
    "\n",
    "def collate(input):\n",
    "    pun_marks = [\",\", \".\", \"?\", \"!\", \";\", \":\", \"-\", \"â€”\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"'\", \"\\\"\", \"`\"]\n",
    "    output = \"\"\n",
    "    Capital = True\n",
    "    Dash = False\n",
    "    for i in range(len(input)):\n",
    "        if input[i] in pun_marks:\n",
    "            output += input[i]\n",
    "            if input[i] in [\".\", \"(\"]:\n",
    "                Capital = True\n",
    "            if input[i] in [\"-\", \"'\"]:\n",
    "                Dash = True\n",
    "            else:\n",
    "                Dash = False\n",
    "        else:\n",
    "            str = \"\"\n",
    "            if (Dash == False):\n",
    "                str += \" \"\n",
    "            if Capital:\n",
    "                str += input[i].capitalize()\n",
    "                Capital = False\n",
    "            else:\n",
    "                str += input[i]\n",
    "            output += str\n",
    "    return output\n",
    "\n",
    "audio_paths = [\"shaunakrecording.mp3\"]\n",
    "\n",
    "transcriptions = w2vmodel.transcribe(audio_paths)\n",
    "input = transcriptions[0][\"transcription\"]\n",
    "input = input.split()\n",
    "\n",
    "#(1) is a strategy where tokens are used to determine lexicographic distance\n",
    "#(2) is a strategy where replaced words \n",
    "for t in range(1):\n",
    "    # output = [] #(2)\n",
    "    for i in range(len(input)):\n",
    "        temp = input[i]\n",
    "        token = tokenizer(temp)['input_ids'][1]\n",
    "        input[i] = \"[MASK]\"\n",
    "        apiint = unmasker(' '.join(input))\n",
    "        dist = []\n",
    "        for r in range(5):\n",
    "            # if (np.abs((apiint[r]['token'] - token)) < 2): #(1)\n",
    "            dist.append(levenshtein_distance(temp, apiint[r]['token_str']))\n",
    "        lindex = 0\n",
    "        l = dist[0]\n",
    "        for r in range(5):\n",
    "            if dist[r] < l:\n",
    "                lindex = r\n",
    "                l = dist[r]\n",
    "        if l <= 2:\n",
    "            input[i] = apiint[lindex]['token_str']\n",
    "            # output.append(apiint[lindex]['token_str']) #(2)\n",
    "        else:\n",
    "            input[i] = temp\n",
    "            # output.append(temp) #(2)\n",
    "        # input[i] = temp #(2)\n",
    "\n",
    "for t in range(1):\n",
    "    inndex = 1\n",
    "    for i in range(len(input)):\n",
    "        input.insert(inndex, \"[MASK]\")\n",
    "        # print(' '.join(input))\n",
    "        apiint = unmasker(' '.join(input))\n",
    "        if (apiint[0]['token'] < 1500):\n",
    "            input[inndex] = apiint[0][\"token_str\"]\n",
    "            inndex += 2\n",
    "        else:\n",
    "            del input[inndex]\n",
    "            inndex += 1\n",
    "\n",
    "print(collate(input))\n",
    "\n",
    "# In comparison, a plain autocorrect gives this output:\n",
    "\n",
    "# \"The b-movie by Jerry Sinclair, the sound of buzzing \n",
    "# bees, can be heard according to all known laws of \n",
    "# aviation that is no way for b to be able to fly its \n",
    "# wings are too small to get its start little body off \n",
    "# the ground, the be, of course, flies anyway because \n",
    "# bees don't care what humans think is possible. \n",
    "# Barbuda is guaranteed one member of the House of \n",
    "# Representatives and two members of the Senate.\"\n",
    "\n",
    "# - https://huggingface.co/oliverguhr/spelling-correction-english-base?text=lets+do+a+comparsion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
